<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models</title>
    <meta name="description"
        content="Project page for CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models (Under Review)">

    <!-- Fonts and Icons -->
    <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/wanteddev/wanted-sans@v1.0.1/packages/wanted-sans/fonts/webfonts/variable/split/WantedSansVariable.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="style.css">

    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

    <!-- Sidebar Navigation -->
    <div class="sidebar">
        <a href="#overview" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Overview</span>
        </a>
        <a href="#analysis" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Analysis</span>
        </a>
        <a href="#cameo" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">CAMEO</span>
        </a>
        <a href="#results" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Results</span>
        </a>
        <a href="#citation" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Citation</span>
        </a>
    </div>

    <!-- Hero Section -->
    <section id="overview" class="hero-section">
        <div class="hero-container">
            <h1 class="hero-title">
                <span class="gradient-text">CAMEO</span>
                <video autoplay loop muted playsinline class="hero-video-icon">
                    <source src="assets/cameoji.webm" type="video/webm">
                </video>
                : Correspondence-Attention Alignment for Multi-View Diffusion Models
            </h1>
            <p class="hero-status">arXiv 2025</p>

            <!-- Authors -->
            <!-- Authors -->
            <div class="hero-authors">
                <span>Minkyung Kwon<sup>*1</sup></span>
                <span>Jinhyeok Choi<sup>*1</sup></span>
                <span>Jiho Park<sup>*1</sup></span>
                <span>Seonghu Jeon<sup>1</sup></span>
                <span>Jinhyuk Jang<sup>1</sup></span>
                <span>Junyoung Seo<sup>1</sup></span>
                <span>Minseop Kwak<sup>1</sup></span>
                <span>Jin-Hwa Kim<sup>&dagger;2,3</sup></span>
                <span>Seungryong Kim<sup>&dagger;1</sup></span>
            </div>

            <div class="hero-affiliations">
                <span><sup>1</sup>KAIST AI</span>
                <span><sup>2</sup>NAVER AI Lab</span>
                <span><sup>3</sup>SNU AIIS</span>
            </div>

            <div class="hero-notes">
                <span>*: Equal contribution</span>
                <span>&dagger;: Co-corresponding author</span>
            </div>

            <!-- Link Buttons -->
            <div class="hero-buttons">
                <a href="#" class="btn">
                    <i class="fa-solid fa-file-pdf"></i> Paper
                </a>
                <a href="#" class="btn btn-outline">
                    <i class="fa-brands fa-github"></i> Code (Coming Soon)
                </a>
                <a href="#bibtex" class="btn btn-outline">
                    <i class="fa-solid fa-quote-right"></i> BibTeX
                </a>
            </div>
        </div>

        <!-- Teaser Section -->
        <div class="teaser-container">
            <!-- TL;DR Box -->
            <div class="tldr-box">
                <div class="tldr-content">
                    <span class="tldr-label">TL;DR</span>
                    <p class="tldr-text">
                        We discover that multi-view diffusion models naturally learn 3D geometry in specific attention
                        layers.
                        <span class="tldr-highlight">CAMEO</span> aligns this internal attention with geometric
                        correspondence,<br>achieving
                        <span class="tldr-highlight">faster convergence</span> and <span class="tldr-highlight">superior
                            geometric consistency</span>.
                    </p>
                </div>
            </div>

            <!-- Image Comparison Sliders -->
            <div class="comparison-grid">
                <!-- Result 1 -->
                <div class="comparison-item">
                    <div class="img-comp-container" id="compare1">
                        <div class="img-comp-img">
                            <img src="https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?q=80&w=1600&auto=format&fit=crop"
                                alt="CAMEO (Ours)">
                            <div class="img-comp-badge cameo">CAMEO</div>
                        </div>
                        <div class="img-comp-img img-comp-overlay">
                            <img src="https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?q=80&w=1600&auto=format&fit=crop&blur=50"
                                style="filter: blur(4px) contrast(1.2);" alt="Baseline">
                            <div class="img-comp-badge baseline">Baseline</div>
                        </div>
                    </div>
                    <div class="comparison-label">Large Viewpoint Change</div>
                </div>

                <!-- Result 2 -->
                <div class="comparison-item">
                    <div class="img-comp-container" id="compare2">
                        <div class="img-comp-img">
                            <img src="https://images.unsplash.com/photo-1586023492125-27b2c045efd7?q=80&w=1600&auto=format&fit=crop"
                                alt="CAMEO (Ours)">
                            <div class="img-comp-badge cameo">CAMEO</div>
                        </div>
                        <div class="img-comp-img img-comp-overlay">
                            <img src="https://images.unsplash.com/photo-1586023492125-27b2c045efd7?q=80&w=1600&auto=format&fit=crop"
                                style="filter: hue-rotate(30deg) blur(2px);" alt="Baseline">
                            <div class="img-comp-badge baseline">Baseline</div>
                        </div>
                    </div>
                    <div class="comparison-label">Complex Geometry</div>
                </div>
            </div>
        </div>
    </section>

    <!-- Abstract -->
    <section class="section alt-bg">
        <div class="container">
            <h2 class="section-title">Abstract</h2>
            <div class="abstract-text">
                <p>
                    Multi-view diffusion models have recently established themselves as a powerful paradigm for novel
                    view synthesis, generating diverse images with high visual fidelity. However, the underlying
                    mechanisms
                    that enable these models to maintain geometric consistency across different viewpoints have remained
                    largely unexplored. In this work, we conduct an in-depth analysis of the 3D self-attention layers
                    within
                    these models. We empirically verify that <strong>geometric correspondence naturally emerges in
                        specific
                        attention layers</strong> during training, allowing the model to attend to spatially
                    corresponding regions across reference and target views.
                </p>
                <p>
                    Despite this emergent capability, our analysis reveals that the implicit correspondence signal is
                    often incomplete and fragile, particularly degrading under scenarios involving complex geometries or
                    large
                    viewpoint changes. Addressing this limitation, we introduce <strong>CAMEO</strong>
                    (Correspondence-Attention Alignment), a training framework that explicitly supervises the model's
                    attention maps using dense geometric correspondence priors. By applying this supervision to just a
                    single, optimal attention layer (Layer 10), CAMEO significantly enhances the model's structural
                    understanding. Our experiments demonstrate that CAMEO <strong>reduces the training iterations
                        required for convergence by 50%</strong> while consistently outperforming baseline models in
                    geometric
                    fidelity on challenging datasets such as RealEstate10K and CO3D.
                </p>
            </div>
        </div>
    </section>

    <!-- Analysis Section -->
    <section id="analysis" class="section">
        <div class="container">
            <h2 class="section-title">Analysis</h2>
            <p>
                To understand the internal mechanisms governing geometric consistency in multi-view diffusion models, we
                analyzed its 3D self-attention maps of CAT3D. We discovered that geometric correspondence naturally
                emerges specifically in <strong>Layer 10</strong>, serving as a critical signal for view-consistent
                generation.
            </p>

            <div>
                <h3 class="analysis-subtitle">Emergence of Geometry in Layer 10</h3>

                <div class="analysis-image-container">
                    <img src="assets/analysis_1.svg"
                        onerror="this.src='https://placehold.co/1200x300/e2e8f0/475569?text=Figure+3:+Attention+Maps'"
                        class="analysis-image" alt="Emergence of Geometry in Layer 10">
                </div>

                <div class="results-caption">
                    <p>
                        <strong>Visualizing Attention Maps.</strong> Comparison between Early Layers vs. Layer 10.
                    </p>
                </div>

                <p>
                    Our layer-wise analysis reveals a distinct contrast in behavior. The shallow layers (e.g., Layers
                    2â€“6) exhibit significant noise and fail to establish meaningful connections between views. In
                    contrast, <strong>Layer 10</strong> (in the CAT3D model) spontaneously demonstrates a strong
                    emergent ability to capture
                    geometric correspondence. Even without explicit supervision, the attention mechanism in this layer
                    naturally focuses on geometrically corresponding points across different views, acting as the
                    primary internal carrier of geometric information.
                </p>
            </div>

            <div>
                <h3 class="analysis-subtitle">Causal Role of Layer 10</h3>

                <div class="analysis-image-container">
                    <img src="assets/analysis_2.svg"
                        onerror="this.src='https://placehold.co/1200x300/e2e8f0/475569?text=Figure+4:+Perturbation+Analysis'"
                        class="analysis-image" alt="Causal Role of Layer 10">
                </div>

                <div class="results-caption">
                    <p>
                        <strong>Perturbation Analysis.</strong> Result of perturbing Layer 10 vs. other layers.
                    </p>
                </div>

                <p>
                    To verify the causal relationship between this emergent correspondence and generation quality, we
                    conducted a perturbation analysis. While perturbing earlier layers leaves the output nearly
                    unchanged, perturbing <strong>Layer 10</strong> leads to a complete collapse of the scene's
                    geometric structure. This proves that the correspondence signal in Layer 10 is not just an artifact
                    but a critical component for maintaining view consistency.
                </p>
            </div>

            <div>
                <h3 class="analysis-subtitle">Quantitative Verification</h3>

                <div id="analysis-charts-container" class="analysis-charts-container">
                    <img src="assets/analysis_3a.svg" style="width: 100%; height: auto;" alt="Layer Index Analysis">
                    <img src="assets/analysis_3b.svg" style="width: 100%; height: auto;" alt="PSNR Analysis">
                    <img src="assets/analysis_3c.svg" style="width: 100%; height: auto;"
                        alt="Viewpoint Rotation Analysis">
                </div>

                <div class="results-caption">
                    <p>
                        <strong>Quantitative Analysis.</strong> (Left) Precision across layers, (Middle) Precision vs.
                        Training Iterations, (Right) Precision under viewpoint rotation.
                    </p>
                </div>

                <p>
                    We quantitatively evaluated the correspondence precision on the NAVI dataset. Our analysis
                    highlights three key findings:
                </p>
                <ul
                    style="list-style-type: disc; margin-left: 1.5rem; margin-bottom: 1.5rem; color: var(--color-text-main); font-size: 1.2rem; line-height: 1.625;">
                    <li style="margin-bottom: 0.5rem;">
                        <strong>Correlation with Quality:</strong> As shown in the training dynamics, there is a strong
                        positive correlation between correspondence precision and generation quality (PSNR). As the
                        model learns better correspondence, the visual quality improves, confirming that correspondence
                        underpins synthesis performance.
                    </li>
                    <li style="margin-bottom: 0.5rem;">
                        <strong>CAMEO Improves Correspondence:</strong> Our proposed method, <strong>CAMEO</strong>,
                        explicitly boosts this correspondence precision, surpassing the baseline and achieving accuracy
                        comparable to dedicated discriminative models like DINOv3.
                    </li>
                    <li>
                        <strong>Limitation (Viewpoint Degradation):</strong> Despite these strengths, the baseline's
                        implicit correspondence is fragile. As the relative rotation angle increases (e.g.,
                        &gt;90&deg;), the precision drops sharply. This "viewpoint degradation" necessitates
                        explicit supervision to maintain robustness in challenging scenarios.
                    </li>
                </ul>
            </div>
        </div>
        </div>
    </section>

    <!-- CAMEO Section -->
    <section id="cameo" class="section alt-bg">
        <div class="container">
            <h2 class="section-title">CAMEO</h2>

            <div class="analysis-image-container">
                <img src="assets/teaser.svg" alt="CAMEO Method Overview" class="analysis-image">
            </div>

            <div class="results-caption">
                <p>
                    <strong>CAMEO Framework Overview.</strong> We introduce Correspondence-Attention Alignment,
                    a training framework that explicitly supervises the model's attention maps using dense geometric
                    correspondence priors.
                </p>
            </div>

            <div class="cameo-description">
                <div>
                    <h3 class="analysis-subtitle">Correspondence-Attention Alignment Loss \(\mathcal{L}_{\text{CAMEO}}\)
                    </h3>

                    <ul
                        style="list-style-type: disc; margin-left: 1.5rem; margin-bottom: 1.5rem; color: var(--color-text-main); font-size: 1.2rem; line-height: 1.625;">
                        <li style="margin-bottom: 0.5rem;">
                            <strong>Cross-View Attention Map \(A^l_{i,j} \in \mathbb{R}^{hw \times hw}\):</strong>
                            The attention matrix from view \(i\) to view \(j\) at layer \(l\).
                            For a query token \(x_i\), the row \(A^l_{i,j}(x_i)\) represents the predicted probability
                            distribution over all tokens in view \(j\).
                        </li>
                        <li style="margin-bottom: 0.5rem;">
                            <strong>Geometric Correspondence Map \(P_{i,j} \in \mathbb{R}^{hw \times hw}\):</strong>
                            The ground-truth correspondence derived from 3D pointmaps.
                            For a query \(x_i\), \(P_{i,j}(x_i)\) is a one-hot vector where the entry
                            corresponding to the matched token \(x_j\) is 1, and all others are 0.
                        </li>
                    </ul>
                    <p>
                        CAMEO minimizes the Cross-Entropy loss between the predicted attention \(A\) and the
                        ground-truth correspondence \(P\), to ensure the model attends to physically correct regions
                        across views:
                        \[ \mathcal{L}_{\text{CAMEO}} = \sum_{i,j} \text{CE}(A^l_{i,j}, P_{i,j}) \]
                    </p>
                    <p>
                        <strong>Simple, Targeted & Model-Agnostic:</strong> CAMEO introduces a straightforward
                        supervision strategy by aligning the cross-view attention map with geometric correspondence at a
                        <strong>single target layer (Layer 10)</strong>. This simple yet effective approach propagates
                        geometric awareness throughout the network without architectural redesigns. Furthermore, CAMEO
                        is universally applicable, demonstrating consistent improvements in geometric consistency on
                        both <strong>Stable Diffusion 2.1</strong> (UNet-based) and <strong>Hunyuan-DiT</strong>
                        (Transformer-based) without compromising generation quality.
                    </p>
                </div>


            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section id="results" class="section">
        <div class="container">

            <!-- 1. Quantitative Results -->
            <div class="results-block">
                <h2 class="section-title">Quantitative Results</h2>
                <div id="carousel-quan" class="carousel-container">
                    <!-- Injected by JS -->
                </div>
            </div>

            <!-- 2. Qualitative Results -->
            <div class="results-block">
                <h2 class="section-title">Qualitative Results</h2>
                <div id="carousel-qual" class="carousel-container">
                    <!-- Injected by JS -->
                </div>
            </div>

            <!-- 3. Ablation Study -->
            <div class="results-block">
                <h2 class="section-title">Ablation Study</h2>
                <div id="carousel-abl" class="carousel-container">
                    <!-- Injected by JS -->
                </div>
            </div>

        </div>
    </section>

    <!-- Citation Section -->
    <section id="citation" class="citation-section">
        <div class="container">
            <h2 class="section-title" style="font-size: 1.5rem; border: none; margin-bottom: 1rem;">Citation</h2>
            <div class="citation-block group">
                <button onclick="copyBibtex()" class="citation-copy-btn">
                    <i class="fa-regular fa-copy"></i> Copy
                </button>
                <pre class="citation-code"><code id="bibtex-text">@article{kwon2026cameo,
  title={CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models},
  author={Kwon, Minkyung and Choi, Jinhyeok and Park, Jiho and Jeon, Seonghu and Jang, Jinhyuk and Seo, Junyoung and Kwak, Min-Seop and Kim, Jin-Hwa and Kim, Seungryong},
  journal={arXiv preprint arXiv:26xx.xxxxx},
  year={2026}
}</code></pre>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models.</p>
        </div>
    </footer>

    <script>
        // Generic Carousel Class
        class Carousel {
            constructor(containerId, data, renderItem) {
                this.container = document.getElementById(containerId);
                this.data = data;
                this.renderItem = renderItem;
                this.currentIndex = 0;
                this.totalSlides = data.length;

                this.init();

                // Handle resize
                window.addEventListener('resize', () => this.updateHeight());

                // Handle image load for height update
                this.container.addEventListener('load', () => this.updateHeight(), true);
            }

            init() {
                this.container.innerHTML = `
                    <div class="carousel-viewport">
                        <div class="carousel-track">
                            ${this.data.map(item => `
                                <div class="carousel-slide">
                                    ${this.renderItem(item)}
                                </div>
                            `).join('')}
                        </div>
                    </div>
                    
                    <button class="carousel-nav-btn prev">
                        <i class="fa-solid fa-chevron-left"></i>
                    </button>
                    <button class="carousel-nav-btn next">
                        <i class="fa-solid fa-chevron-right"></i>
                    </button>

                    <div class="carousel-dots">
                        ${this.data.map((_, i) => `
                            <button class="carousel-dot ${i === 0 ? 'active' : ''}" data-index="${i}"></button>
                        `).join('')}
                    </div>
                `;

                this.track = this.container.querySelector('.carousel-track');
                this.dots = this.container.querySelectorAll('.carousel-dots button');

                this.container.querySelector('.carousel-nav-btn.prev').onclick = () => this.move(-1);
                this.container.querySelector('.carousel-nav-btn.next').onclick = () => this.move(1);
                this.dots.forEach((dot, i) => dot.onclick = () => this.goTo(i));
            }

            move(direction) {
                this.currentIndex = (this.currentIndex + direction + this.totalSlides) % this.totalSlides;
                this.update();
            }

            goTo(index) {
                this.currentIndex = index;
                this.update();
            }

            update() {
                this.track.style.transform = `translateX(-${this.currentIndex * 100}%)`;
                this.dots.forEach((dot, i) => {
                    dot.className = `carousel-dot ${i === this.currentIndex ? 'active' : ''}`;
                });
                this.updateHeight();
            }

            updateHeight() {
                const slides = this.container.querySelectorAll('.carousel-slide');
                if (slides[this.currentIndex]) {
                    const height = slides[this.currentIndex].offsetHeight;
                    this.container.querySelector('.carousel-viewport').style.height = `${height}px`;
                }
            }
        }

        // Data & Render Logic
        const quantitativeData = [
            {
                title: "RealEstate10K",
                desc: "CAMEO achieves a PSNR of 19.4 at only 80k iterations, a level of quality that the baseline model fails to reach even after 160k iterations. This translates to a 2x acceleration in training time.",
                image: "assets/exp_re10k_graph.svg"
            },
            {
                title: "CO3D",
                desc: "On the CO3D dataset, CAMEO consistently outperforms the baseline across all metrics, demonstrating superior geometric consistency and visual fidelity.",
                image: "assets/exp_co3d_graph.svg"
            }
        ];

        const qualitativeData = [
            {
                title: "Co3D",
                desc: "CAMEO preserves sharp structural details and maintains consistency across large viewpoint changes, where baselines often fail.",
                items: [
                    {
                        ref1: "assets/co3d/example1/ref1.png",
                        ref2: "assets/co3d/example1/ref2.png",
                        gt: "assets/co3d/example1/GT.png",
                        cameo: "assets/co3d/example1/cameo.png",
                        baseline: "assets/co3d/example1/cat3d.png"
                    },
                    {
                        ref1: "assets/co3d/example2/ref1.png",
                        ref2: "assets/co3d/example2/ref2.png",
                        gt: "assets/co3d/example2/GT.png",
                        cameo: "assets/co3d/example2/cameo.png",
                        baseline: "assets/co3d/example2/cat3d.png"
                    },
                    {
                        ref1: "assets/co3d/example3/ref1.png",
                        ref2: "assets/co3d/example3/ref2.png",
                        gt: "assets/co3d/example3/GT.png",
                        cameo: "assets/co3d/example3/cameo.png",
                        baseline: "assets/co3d/example3/cat3d.png"
                    },
                    {
                        ref1: "assets/co3d/example4/ref1.png",
                        ref2: "assets/co3d/example4/ref2.png",
                        gt: "assets/co3d/example4/GT.png",
                        cameo: "assets/co3d/example4/cameo.png",
                        baseline: "assets/co3d/example4/cat3d.png"
                    }
                ]
            },
            {
                title: "RealEstate10K",
                desc: "CAMEO demonstrates robust performance on RealEstate10K, handling complex indoor scenes with high fidelity. (Placeholder images)",
                items: [
                    {
                        ref1: "assets/re10k/example1/ref1.jpeg",
                        ref2: "assets/re10k/example1/ref2.jpeg",
                        gt: "assets/re10k/example1/GT.jpeg",
                        cameo: "assets/re10k/example1/cameo.jpeg",
                        baseline: "assets/re10k/example1/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/re10k/example2/ref1.jpeg",
                        ref2: "assets/re10k/example2/ref2.jpeg",
                        gt: "assets/re10k/example2/GT.jpeg",
                        cameo: "assets/re10k/example2/cameo.jpeg",
                        baseline: "assets/re10k/example2/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/re10k/example3/ref1.jpeg",
                        ref2: "assets/re10k/example3/ref2.jpeg",
                        gt: "assets/re10k/example3/GT.jpeg",
                        cameo: "assets/re10k/example3/cameo.jpeg",
                        baseline: "assets/re10k/example3/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/re10k/example4/ref1.jpeg",
                        ref2: "assets/re10k/example4/ref2.jpeg",
                        gt: "assets/re10k/example4/GT.jpeg",
                        cameo: "assets/re10k/example4/cameo.jpeg",
                        baseline: "assets/re10k/example4/cat3d.jpeg"
                    }
                ]
            },
            {
                title: "DTU (Out-of-domain)",
                desc: "Even on out-of-domain datasets like DTU, CAMEO maintains structural consistency better than baselines. (Placeholder images)",
                items: [
                    {
                        ref1: "assets/dtu/example3/ref1.jpeg",
                        ref2: "assets/dtu/example3/ref2.jpeg",
                        gt: "assets/dtu/example3/GT.jpeg",
                        cameo: "assets/dtu/example3/cameo.jpeg",
                        baseline: "assets/dtu/example3/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/dtu/example4/ref1.jpeg",
                        ref2: "assets/dtu/example4/ref2.jpeg",
                        gt: "assets/dtu/example4/GT.jpeg",
                        cameo: "assets/dtu/example4/cameo.jpeg",
                        baseline: "assets/dtu/example4/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/dtu/example1/ref1.jpeg",
                        ref2: "assets/dtu/example1/ref2.jpeg",
                        gt: "assets/dtu/example1/GT.jpeg",
                        cameo: "assets/dtu/example1/cameo.jpeg",
                        baseline: "assets/dtu/example1/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/dtu/example2/ref1.jpeg",
                        ref2: "assets/dtu/example2/ref2.jpeg",
                        gt: "assets/dtu/example2/GT.jpeg",
                        cameo: "assets/dtu/example2/cameo.jpeg",
                        baseline: "assets/dtu/example2/cat3d.jpeg"
                    }
                ]
            }
        ];

        // Render Functions
        function renderQuantitative(item) {
            return `
                <div class="results-slide-content">
                    <h3 class="results-slide-title">${item.title}</h3>
                    <div class="analysis-image-container" style="padding: 0 20px;">
                        <img src="${item.image}" style="width: 100%; height: auto;" alt="${item.title}">
                    </div>
                    
                    <div class="results-caption">
                        <p>${item.desc}</p>
                    </div>
                </div>
            `;
        }

        function renderQualitativeCard(item, syncGroup = null) {
            const syncAttr = syncGroup ? `data-sync-group="${syncGroup}"` : '';
            return `
                <div class="qual-grid">
                    <!-- Column 1: Reference Images -->
                    <div class="qual-col">
                        <div class="qual-header">References</div>
                        <div class="qual-ref-stack">
                            <img src="${item.ref1}" class="qual-ref-img" alt="Reference 1">
                            <img src="${item.ref2}" class="qual-ref-img" alt="Reference 2">
                        </div>
                    </div>

                    <!-- Column 2: Ground Truth -->
                    <div class="qual-col">
                        <div class="qual-header">Ground Truth</div>
                        <img src="${item.gt}" class="qual-main-img" alt="Ground Truth">
                    </div>

                    <!-- Column 3: Generated View -->
                    <div class="qual-col">
                        <div class="qual-header">Generated View</div>
                        ${item.baseline ? `
                            <div class="img-comp-container">
                                <div class="img-comp-img">
                                    <img src="${item.cameo}" alt="CAMEO">
                                    <div class="img-comp-badge cameo">CAMEO</div>
                                </div>
                                <div class="img-comp-img img-comp-overlay" ${syncAttr}>
                                    <img src="${item.baseline}" alt="CAT3D">
                                    <div class="img-comp-badge baseline">CAT3D</div>
                                </div>
                            </div>
                        ` : `
                            <img src="${item.cameo}" class="qual-main-img" alt="CAMEO">
                        `}
                    </div>
                </div>
            `;
        }

        function renderQualitativeSlide(slide) {
            return `
                <div class="results-slide-content">
                    <h3 class="results-slide-title">${slide.title}</h3>
                    
                    <div class="qual-pair-grid">
                        ${slide.items.map(item => renderQualitativeCard(item, 'qual-sync')).join('')}
                    </div>

                    <div class="results-caption">
                        <p>${slide.desc}</p>
                    </div>
                </div>
            `;
        }


        // Chart Generation


        const ablationData = [
            {
                title: 'Ablation Study',
                desc: 'This study presents a comprehensive ablation of our design choices on RealEstate10K. We further investigate the optimal layer for supervision. Our full model (bold) consistently achieves the best performance.',
                tables: `
                    <div class="ablation-tables-row" style="display: flex; gap: 2rem; justify-content: center; align-items: flex-start; flex-wrap: wrap;">
                        <!-- Table 3: Layer Ablation (Existing) -->
                        <div class="ablation-item" style="flex: 1; min-width: 300px;">
                            <div class="table-caption">
                                <strong>Layer Ablation.</strong> Comparison of applying CAMEO supervision to different attention layers.
                            </div>
                            <table class="results-table">
                                <thead><tr><th>Layer</th><th>Iter.</th><th>PSNR&uarr;</th><th>SSIM&uarr;</th><th>LPIPS&darr;</th></tr></thead>
                                <tbody>
                                    <tr><td>2</td><td rowspan="5" style="vertical-align: middle;">80k</td><td>18.80</td><td>0.676</td><td><strong>0.315</strong></td></tr>
                                    <tr><td>4</td><td>18.78</td><td>0.673</td><td>0.320</td></tr>
                                    <tr><td>6</td><td>18.19</td><td>0.663</td><td>0.326</td></tr>
                                    <tr><td>7</td><td>18.60</td><td>0.666</td><td>0.323</td></tr>
                                    <tr class="highlight-row"><td><strong>10</strong></td><td><strong>19.08</strong></td><td><strong>0.681</strong></td><td>0.316</td></tr>
                                </tbody>
                            </table>
                        </div>

                        <!-- Table 2: General Ablation (New) -->
                        <div class="ablation-item" style="flex: 1; min-width: 300px;">
                            <div class="table-caption">
                                <strong>Ablation Study of CAMEO on RealEstate10K.</strong> All at 40k iterations.
                            </div>
                            <table class="results-table">
                                <thead><tr><th>Part</th><th>Factor</th><th>Variant</th><th>PSNR&uarr;</th><th>SSIM&uarr;</th><th>LPIPS&darr;</th></tr></thead>
                                <tbody>
                                    <!-- (a) MLP head -->
                                    <tr><td rowspan="2">(a)</td><td rowspan="2" style="vertical-align: middle;">MLP head</td><td style="text-align: center;">&times;</td><td>18.08</td><td>0.653</td><td>0.343</td></tr>
                                    <tr class="highlight-row"><td style="text-align: center; padding-left: 0;">&check;</td><td><strong>18.31</strong></td><td><strong>0.658</strong></td><td><strong>0.337</strong></td></tr>
                                    <tr class="separator-row"><td colspan="6"></td></tr>
                                    
                                    <!-- (b) Loss weight -->
                                    <tr><td rowspan="3">(b)</td><td rowspan="3" style="vertical-align: middle;">Loss weight (&lambda;)</td><td style="text-align: center;">0.01</td><td>18.22</td><td>0.657</td><td>0.351</td></tr>
                                    <tr class="highlight-row"><td style="text-align: center; padding-left: 0;"><strong>0.02</strong></td><td>18.31</td><td><strong>0.658</strong></td><td><strong>0.337</strong></td></tr>
                                    <tr><td style="text-align: center; padding-left: 0;">0.03</td><td><strong>18.37</strong></td><td>0.656</td><td>0.377</td></tr>
                                    <tr class="separator-row"><td colspan="6"></td></tr>

                                    <!-- (c) Loss type -->
                                    <tr><td rowspan="2">(c)</td><td rowspan="2" style="vertical-align: middle;">Loss type</td><td style="text-align: center;">L1</td><td>17.84</td><td>0.641</td><td>0.342</td></tr>
                                    <tr class="highlight-row"><td style="text-align: center; padding-left: 0;">CE(&middot;)</td><td><strong>18.31</strong></td><td><strong>0.658</strong></td><td><strong>0.337</strong></td></tr>
                                    <tr class="separator-row"><td colspan="6"></td></tr>

                                    <!-- (d) Consistency threshold -->
                                    <tr><td rowspan="3">(d)</td><td rowspan="3" style="vertical-align: middle;">Consistency<br>threshold (&tau;)</td><td style="text-align: center;"><span style="font-size: 1.4em; font-weight: bold;">&infin;</span></td><td>18.18</td><td>0.656</td><td>0.341</td></tr>
                                    <tr><td style="text-align: center; padding-left: 0;">3</td><td>17.49</td><td>0.648</td><td>0.338</td></tr>
                                    <tr class="highlight-row"><td style="text-align: center; padding-left: 0;"><strong>1.5</strong></td><td><strong>18.31</strong></td><td><strong>0.658</strong></td><td><strong>0.337</strong></td></tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                `,
                qualItems: null // No qualitative results for this slide
            },
            {
                title: 'Model Generalization: Hunyuan-DiT',
                desc: 'Validation on a Transformer-based model. CAMEO consistently outperforms the baseline across all metrics and produces sharper visual details.',
                tables: `
                    <div class="ablation-item">
                        <div class="table-caption">
                            <strong>CAMEO on Hunyuan-DiT.</strong>
                        </div>
                        <table class="results-table">
                            <thead><tr><th>Model</th><th>Iter.</th><th>PSNR&uarr;</th><th>SSIM&uarr;</th><th>LPIPS&darr;</th></tr></thead>
                            <tbody>
                                <tr><td>Hunyuan-DiT</td><td rowspan="2" style="vertical-align: middle;">20k</td><td>14.40</td><td>0.533</td><td>0.459</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>16.17</strong></td><td><strong>0.575</strong></td><td><strong>0.373</strong></td></tr>
                                <tr class="separator-row"><td colspan="5"></td></tr>
                                <tr><td>Hunyuan-DiT</td><td rowspan="2" style="vertical-align: middle;">40k</td><td>17.00</td><td>0.594</td><td>0.321</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>17.57</strong></td><td><strong>0.612</strong></td><td><strong>0.294</strong></td></tr>
                                <tr class="separator-row"><td colspan="5"></td></tr>
                                <tr><td>Hunyuan-DiT</td><td rowspan="2" style="vertical-align: middle;">60k</td><td>17.55</td><td>0.610</td><td>0.289</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>18.52</strong></td><td><strong>0.639</strong></td><td><strong>0.260</strong></td></tr>
                                <tr class="separator-row"><td colspan="5"></td></tr>
                                <tr><td>Hunyuan-DiT</td><td rowspan="2" style="vertical-align: middle;">120k</td><td>19.30</td><td>0.661</td><td>0.218</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>19.75</strong></td><td><strong>0.677</strong></td><td><strong>0.211</strong></td></tr>
                            </tbody>
                        </table>
                    </div>
                `,
                qualItems: [
                    {
                        ref1: "assets/dit/example1/ref1.jpeg",
                        ref2: "assets/dit/example1/ref2.jpeg",
                        gt: "assets/dit/example1/GT.jpeg",
                        cameo: "assets/dit/example1/cameo.jpeg",
                        baseline: "assets/dit/example1/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/dit/example2/ref1.jpeg",
                        ref2: "assets/dit/example2/ref2.jpeg",
                        gt: "assets/dit/example2/GT.jpeg",
                        cameo: "assets/dit/example2/cameo.jpeg",
                        baseline: "assets/dit/example2/cat3d.jpeg"
                    }
                ]
            },
            {
                title: 'Model Generalization: MVGenMaster',
                desc: 'Performance comparison on the MVGenMaster model (UNet-based). CAMEO accelerates convergence and improves final quality.',
                tables: `
                    <div class="ablation-item">
                        <div class="table-caption">
                            <strong>CAMEO on MVGenMaster.</strong>
                        </div>
                        <table class="results-table">
                            <thead><tr><th>Model</th><th>Iter.</th><th>PSNR&uarr;</th><th>SSIM&uarr;</th><th>LPIPS&darr;</th></tr></thead>
                            <tbody>
                                <tr><td>MVGenMaster</td><td rowspan="2" style="vertical-align: middle;">20k</td><td>17.35</td><td>0.649</td><td>0.327</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>18.31</strong></td><td><strong>0.671</strong></td><td><strong>0.315</strong></td></tr>
                                <tr class="separator-row"><td colspan="5"></td></tr>
                                <tr><td>MVGenMaster</td><td rowspan="2" style="vertical-align: middle;">40k</td><td>18.64</td><td><strong>0.682</strong></td><td>0.306</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>18.70</strong></td><td>0.668</td><td><strong>0.305</strong></td></tr>
                                <tr class="separator-row"><td colspan="5"></td></tr>
                                <tr><td>MVGenMaster</td><td rowspan="2" style="vertical-align: middle;">60k</td><td>18.84</td><td>0.678</td><td>0.305</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>19.21</strong></td><td><strong>0.695</strong></td><td><strong>0.304</strong></td></tr>
                                <tr class="separator-row"><td colspan="5"></td></tr>
                                <tr><td>MVGenMaster</td><td rowspan="2" style="vertical-align: middle;">120k</td><td>19.45</td><td>0.699</td><td>0.295</td></tr>
                                <tr class="highlight-row"><td><strong>w/ CAMEO</strong></td><td><strong>19.56</strong></td><td><strong>0.700</strong></td><td><strong>0.292</strong></td></tr>
                            </tbody>
                        </table>
                    </div>
                `,
                qualItems: [
                    {
                        ref1: "assets/mvgenmaster/example1/ref1.jpeg",
                        ref2: "assets/mvgenmaster/example1/ref2.jpeg",
                        gt: "assets/mvgenmaster/example1/GT.jpeg",
                        cameo: "assets/mvgenmaster/example1/cameo.jpeg",
                        baseline: "assets/mvgenmaster/example1/cat3d.jpeg"
                    },
                    {
                        ref1: "assets/mvgenmaster/example2/ref1.jpeg",
                        ref2: "assets/mvgenmaster/example2/ref2.jpeg",
                        gt: "assets/mvgenmaster/example2/GT.jpeg",
                        cameo: "assets/mvgenmaster/example2/cameo.jpeg",
                        baseline: "assets/mvgenmaster/example2/cat3d.jpeg"
                    }
                ]
            }
        ];

        function renderAblationSlide(item) {
            // Check if there are qualitative items
            const hasQual = item.qualItems && item.qualItems.length > 0;

            return `
                <div class="results-slide-content">
                    <h3 class="results-slide-title">${item.title}</h3>
                    
                    ${hasQual ? `
                        <div class="ablation-split-container">
                            <!-- Left: Tables -->
                            <div class="ablation-table-col">
                                ${item.tables}
                            </div>

                            <!-- Right: Qualitative -->
                            <div class="ablation-qual-col">
                                <div class="qual-pair-grid">
                                    ${item.qualItems.map(subItem => renderQualitativeCard(subItem, 'abl-sync')).join('')}
                                </div>
                            </div>
                        </div>
                    ` : `
                        <!-- Full width table if no qual items -->
                        <div class="ablation-full-container">
                            ${item.tables}
                        </div>
                    `}

                    <div class="results-caption">
                        <p>${item.desc}</p>
                    </div>
                </div>
            `;
        }

        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            new Carousel('carousel-quan', quantitativeData, renderQuantitative);
            new Carousel('carousel-qual', qualitativeData, renderQualitativeSlide);
            new Carousel('carousel-abl', ablationData, renderAblationSlide);
            initComparisons();
            initScrollSpy();
            initFadeInAnimations();
        });

        // Fade-in Animation
        function initFadeInAnimations() {
            const observerOptions = {
                root: null,
                rootMargin: '0px',
                threshold: 0.1
            };

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        entry.target.classList.add('is-visible');
                        observer.unobserve(entry.target);
                    }
                });
            }, observerOptions);

            const sections = document.querySelectorAll('.section, .hero-section, .citation-section, .footer');
            sections.forEach(section => {
                section.classList.add('fade-in-section');
                observer.observe(section);
            });
        }

        // Image Comparison Slider Logic
        function initComparisons() {
            var x, i;
            // Flags to ensure animation happens once per section
            let hasAnimatedTeaser = false;
            let hasAnimatedQual = false;

            x = document.getElementsByClassName("img-comp-overlay");
            for (i = 0; i < x.length; i++) {
                compareImages(x[i]);
            }

            function compareImages(img) {
                // Check if slider already exists
                if (img.parentElement.querySelector('.img-comp-slider')) {
                    return;
                }

                var slider, clicked = 0, w, h;
                // Use parent container for dimensions to be safe
                w = img.parentElement.offsetWidth;
                h = img.parentElement.offsetHeight;

                var overlayImg = img.getElementsByTagName("img")[0];
                if (overlayImg) {
                    overlayImg.style.width = w + "px";
                    overlayImg.style.maxWidth = "none";
                }

                img.style.width = (w / 2) + "px";

                slider = document.createElement("DIV");
                slider.setAttribute("class", "img-comp-slider");
                img.parentElement.insertBefore(slider, img);

                slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
                slider.style.left = (w / 2) - (slider.offsetWidth / 2) + "px";

                slider.addEventListener("mousedown", slideReady);
                window.addEventListener("mouseup", slideFinish);
                slider.addEventListener("touchstart", slideReady);
                window.addEventListener("touchend", slideFinish);

                // Auto-slide Animation
                const observer = new IntersectionObserver((entries) => {
                    entries.forEach(entry => {
                        if (entry.isIntersecting && !slider.dataset.animated) {
                            let shouldAnimate = false;

                            // Check if it's in Teaser section
                            if (img.closest('.teaser-container') && !hasAnimatedTeaser) {
                                shouldAnimate = true;
                                hasAnimatedTeaser = true;
                            }
                            // Check if it's in Qualitative section
                            else if (img.closest('#carousel-qual') && !hasAnimatedQual) {
                                shouldAnimate = true;
                                hasAnimatedQual = true;
                            }

                            if (shouldAnimate) {
                                slider.dataset.animated = "true";
                                animateSlider();
                            }
                        }
                    });
                }, { threshold: 0.5 });

                observer.observe(img.parentElement);

                function animateSlider() {
                    const start = w / 2;
                    const target = w * 0.25; // Move to left to reveal CAMEO
                    const duration = 1000;
                    const startTime = performance.now();

                    function step(currentTime) {
                        const elapsed = currentTime - startTime;
                        let progress = elapsed / duration;

                        if (progress > 1) progress = 1;

                        let currentPos;
                        // 0 -> 0.5: Center to Left
                        // 0.5 -> 1.0: Left to Center

                        if (progress < 0.5) {
                            const p = progress / 0.5;
                            // Ease out cubic
                            const ease = 1 - Math.pow(1 - p, 3);
                            currentPos = start + (target - start) * ease;
                        } else {
                            const p = (progress - 0.5) / 0.5;
                            // Ease out cubic
                            const ease = 1 - Math.pow(1 - p, 3);
                            currentPos = target + (start - target) * ease;
                        }

                        slide(currentPos);

                        if (progress < 1) {
                            requestAnimationFrame(step);
                        }
                    }

                    requestAnimationFrame(step);
                }

                // Update dimensions on window resize
                window.addEventListener('resize', function () {
                    w = img.parentElement.offsetWidth;
                    h = img.parentElement.offsetHeight;
                    if (overlayImg) {
                        overlayImg.style.width = w + "px";
                    }
                    // Recenter slider vertically
                    slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
                    // Note: We keep the current slider horizontal position (in pixels) 
                    // which might drift on resize, but fixing the image width is most important.
                });

                function slideReady(e) {
                    e.preventDefault();
                    clicked = 1;
                    window.addEventListener("mousemove", slideMove);
                    window.addEventListener("touchmove", slideMove);
                }

                function slideFinish() {
                    clicked = 0;
                }

                function slideMove(e) {
                    var pos;
                    if (clicked == 0) return false;
                    pos = getCursorPos(e);
                    if (pos < 0) pos = 0;
                    if (pos > w) pos = w;
                    slide(pos);
                }

                function getCursorPos(e) {
                    var a, x = 0;
                    e = (e.changedTouches) ? e.changedTouches[0] : e;
                    a = img.getBoundingClientRect();
                    x = e.pageX - a.left;
                    x = x - window.pageXOffset;
                    return x;
                }

                function slide(x, fromSync = false) {
                    img.style.width = x + "px";
                    slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + "px";

                    // Synchronization Logic
                    if (!fromSync && img.dataset.syncGroup) {
                        const groupName = img.dataset.syncGroup;
                        const groupMembers = document.querySelectorAll(`.img-comp-overlay[data-sync-group="${groupName}"]`);

                        groupMembers.forEach(member => {
                            if (member !== img) {
                                // Calculate percentage to handle different widths if necessary (though they should be same)
                                const percentage = x / w;
                                const memberW = member.parentElement.offsetWidth;
                                const memberX = percentage * memberW;

                                // Call slide on the member
                                // We need to access the slide function of the member. 
                                // Since scope is isolated, we can trigger a custom event or expose the function.
                                // Simplest way here: re-implement slide logic or attach function to element.
                                if (member.slideFunc) {
                                    member.slideFunc(memberX, true);
                                }
                            }
                        });
                    }
                }

                // Attach slide function to element for external access
                img.slideFunc = slide;
            }
        }


        // Scroll Spy for Sidebar
        function initScrollSpy() {
            const sections = document.querySelectorAll('section[id]');
            const sidebarLinks = document.querySelectorAll('.sidebar-item');
            const sidebar = document.querySelector('.sidebar');

            const observerOptions = {
                root: null,
                rootMargin: '-50% 0px -50% 0px',
                threshold: 0
            };

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        const id = entry.target.getAttribute('id');

                        // Remove active class from all sidebar items
                        sidebarLinks.forEach(link => {
                            link.classList.remove('active');
                        });

                        // Add active class to the corresponding sidebar item
                        const activeLink = document.querySelector(`.sidebar-item[href="#${id}"]`);
                        if (activeLink) {
                            activeLink.classList.add('active');

                            // Update gradient position
                            const linkRect = activeLink.getBoundingClientRect();
                            const sidebarRect = sidebar.getBoundingClientRect();
                            const relativeTop = linkRect.top - sidebarRect.top;
                            sidebar.style.setProperty('--active-position', `${relativeTop - 32}px`);
                        }
                    }
                });
            }, observerOptions);

            sections.forEach(section => {
                observer.observe(section);
            });
        }

        function copyBibtex() {
            const text = document.getElementById('bibtex-text').innerText;
            navigator.clipboard.writeText(text).then(() => {
                const btn = document.querySelector('.citation-copy-btn');
                const original = btn.innerHTML;
                btn.innerHTML = '<i class="fa-solid fa-check"></i> Copied!';
                setTimeout(() => {
                    btn.innerHTML = original;
                }, 2000);
            });
        }

        // Initialize scroll spy when DOM is ready
        // Initialize charts
        document.addEventListener('DOMContentLoaded', () => {
            initComparisons();
            initScrollSpy();
        });


    </script>
</body>

</html>
```