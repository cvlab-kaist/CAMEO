<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models</title>
    <meta name="description"
        content="Project page for CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models (Under Review)">

    <!-- Fonts and Icons -->
    <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/wanteddev/wanted-sans@v1.0.1/packages/wanted-sans/fonts/webfonts/variable/split/WantedSansVariable.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="style.css">

    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

    <!-- Sidebar Navigation -->
    <div class="sidebar">
        <a href="#overview" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Overview</span>
        </a>
        <a href="#analysis" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Analysis</span>
        </a>
        <a href="#cameo" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">CAMEO</span>
        </a>
        <a href="#results" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Results</span>
        </a>
        <a href="#citation" class="sidebar-item">
            <div class="sidebar-dot"></div>
            <span class="sidebar-label">Citation</span>
        </a>
    </div>

    <!-- Hero Section -->
    <section id="overview" class="hero-section">
        <div class="hero-container">
            <h1 class="hero-title">
                <span class="gradient-text">CAMEO</span>
                <video autoplay loop muted playsinline class="hero-video-icon">
                    <source src="assets/cameoji.webm" type="video/webm">
                </video>
                : Correspondence-Attention Alignment for Multi-View Diffusion Models
            </h1>
            <p class="hero-status">Under Review</p>

            <!-- Authors -->
            <div class="hero-authors">
                <span>Minkyung Kwon<sup>1</sup></span>
                <span>Jinhyeok Choi<sup>1</sup></span>
                <span>Jiho Park<sup>2</sup></span>
                <span>Seonghu Jeon<sup>3</sup></span>
                <span>Jinhyuk Jang<sup>1</sup></span>
                <span>Junyoung Seo<sup>1</sup></span>
                <span>Min-Seop Kwak<sup>1</sup></span>
                <span>Jin-Hwa Kim<sup>4</sup></span>
                <span>Seungryong Kim<sup>1</sup></span>
            </div>

            <div class="hero-affiliations">
                <span><sup>1</sup>KAIST</span>
                <span><sup>2</sup>Yonsei University</span>
                <span><sup>3</sup>Korea University</span>
                <span><sup>4</sup>NAVER</span>
            </div>

            <!-- Link Buttons -->
            <div class="hero-buttons">
                <a href="#" class="btn">
                    <i class="fa-solid fa-file-pdf"></i> Paper
                </a>
                <a href="#" class="btn btn-outline">
                    <i class="fa-brands fa-github"></i> Code (Coming Soon)
                </a>
                <a href="#bibtex" class="btn btn-outline">
                    <i class="fa-solid fa-quote-right"></i> BibTeX
                </a>
            </div>
        </div>

        <!-- Teaser Section -->
        <div class="teaser-container">
            <!-- TL;DR Box -->
            <div class="tldr-box">
                <div class="tldr-content">
                    <span class="tldr-label">TL;DR</span>
                    <p class="tldr-text">
                        We discover that multi-view diffusion models naturally learn 3D geometry in specific attention
                        layers.
                        <span class="tldr-highlight">CAMEO</span> aligns this internal attention with geometric
                        correspondence,<br>achieving
                        <span class="tldr-highlight">2x faster convergence</span> and <span
                            class="tldr-highlight">superior geometric consistency</span>.
                    </p>
                </div>
            </div>

            <!-- Image Comparison Sliders -->
            <div class="comparison-grid">
                <!-- Result 1 -->
                <div class="comparison-item">
                    <div class="img-comp-container" id="compare1">
                        <div class="img-comp-img">
                            <img src="https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?q=80&w=1600&auto=format&fit=crop"
                                alt="CAMEO (Ours)">
                            <div class="img-comp-badge cameo">CAMEO</div>
                        </div>
                        <div class="img-comp-img img-comp-overlay">
                            <img src="https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?q=80&w=1600&auto=format&fit=crop&blur=50"
                                style="filter: blur(4px) contrast(1.2);" alt="Baseline">
                            <div class="img-comp-badge baseline">Baseline</div>
                        </div>
                    </div>
                    <div class="comparison-label">Large Viewpoint Change</div>
                </div>

                <!-- Result 2 -->
                <div class="comparison-item">
                    <div class="img-comp-container" id="compare2">
                        <div class="img-comp-img">
                            <img src="https://images.unsplash.com/photo-1586023492125-27b2c045efd7?q=80&w=1600&auto=format&fit=crop"
                                alt="CAMEO (Ours)">
                            <div class="img-comp-badge cameo">CAMEO</div>
                        </div>
                        <div class="img-comp-img img-comp-overlay">
                            <img src="https://images.unsplash.com/photo-1586023492125-27b2c045efd7?q=80&w=1600&auto=format&fit=crop"
                                style="filter: hue-rotate(30deg) blur(2px);" alt="Baseline">
                            <div class="img-comp-badge baseline">Baseline</div>
                        </div>
                    </div>
                    <div class="comparison-label">Complex Geometry</div>
                </div>
            </div>
        </div>
    </section>

    <!-- Abstract -->
    <section class="section alt-bg">
        <div class="container">
            <h2 class="section-title">Abstract</h2>
            <div class="abstract-text">
                <p>
                    Multi-view diffusion models have recently established themselves as a powerful paradigm for novel
                    view synthesis, generating diverse images with high visual fidelity. However, the underlying
                    mechanisms
                    that enable these models to maintain geometric consistency across different viewpoints have remained
                    largely unexplored. In this work, we conduct an in-depth analysis of the 3D self-attention layers
                    within
                    these models. We empirically verify that <strong>geometric correspondence naturally emerges in
                        specific
                        attention layers</strong> during training, allowing the model to attend to spatially
                    corresponding regions across reference and target views.
                </p>
                <p>
                    Despite this emergent capability, our analysis reveals that the implicit correspondence signal is
                    often incomplete and fragile, particularly degrading under scenarios involving complex geometries or
                    large
                    viewpoint changes. Addressing this limitation, we introduce <strong>CAMEO</strong>
                    (Correspondence-Attention Alignment), a training framework that explicitly supervises the model's
                    attention maps using dense geometric correspondence priors. By applying this supervision to just a
                    single, optimal attention layer (Layer 10), CAMEO significantly enhances the model's structural
                    understanding. Our experiments demonstrate that CAMEO <strong>reduces the training iterations
                        required for convergence by 50%</strong> while consistently outperforming baseline models in
                    geometric
                    fidelity on challenging datasets such as RealEstate10K and CO3D.
                </p>
            </div>
        </div>
    </section>

    <!-- Analysis Section -->
    <section id="analysis" class="section">
        <div class="container">
            <h2 class="section-title">Analysis</h2>


            <div>
                <h3 class="analysis-subtitle">Emergence of Geometry in Layer 10</h3>

                <div class="analysis-image-container">
                    <img src="assets/analysis_1.svg"
                        onerror="this.src='https://placehold.co/1200x300/e2e8f0/475569?text=Figure+3:+Attention+Maps'"
                        class="analysis-image" alt="Emergence of Geometry in Layer 10">
                </div>

                <div class="results-caption">
                    <p>
                        <strong>Visualizing Attention Maps.</strong> Comparison between Early Layers vs. Layer 10.
                    </p>
                </div>

                <p>
                    Our layer-wise analysis reveals a distinct contrast in behavior. The shallow layers (e.g., Layers
                    2â€“6) exhibit significant noise and fail to establish meaningful connections between views. In
                    contrast, <strong>Layer 10</strong> spontaneously demonstrates a strong emergent ability to capture
                    geometric correspondence. Even without explicit supervision, the attention mechanism in this layer
                    naturally focuses on geometrically corresponding points across different views, acting as the
                    primary internal carrier of geometric information.
                </p>
            </div>

            <div>
                <h3 class="analysis-subtitle">Causal Role of Layer 10</h3>

                <div class="analysis-image-container">
                    <img src="assets/analysis_2.svg"
                        onerror="this.src='https://placehold.co/1200x300/e2e8f0/475569?text=Figure+4:+Perturbation+Analysis'"
                        class="analysis-image" alt="Causal Role of Layer 10">
                </div>

                <div class="results-caption">
                    <p>
                        <strong>Perturbation Analysis.</strong> Result of perturbing Layer 10 vs. other layers.
                    </p>
                </div>

                <p>
                    To verify the causal relationship between this emergent correspondence and generation quality, we
                    conducted a perturbation analysis. While perturbing earlier layers leaves the output nearly
                    unchanged, perturbing <strong>Layer 10</strong> leads to a complete collapse of the scene's
                    geometric structure. This proves that the correspondence signal in Layer 10 is not just an artifact
                    but a critical component for maintaining view consistency.
                </p>
            </div>

            <div>
                <h3 class="analysis-subtitle">Quantitative Verification & Limitation</h3>

                <div id="analysis-charts-container" class="analysis-charts-container">
                    <img src="assets/analysis_3a.svg" style="width: 100%; height: auto;" alt="Layer Index Analysis">
                    <img src="assets/analysis_3b.svg" style="width: 100%; height: auto;" alt="PSNR Analysis">
                    <img src="assets/analysis_3c.svg" style="width: 100%; height: auto;"
                        alt="Viewpoint Rotation Analysis">
                </div>

                <div class="results-caption">
                    <p>
                        <strong>Quantitative Analysis.</strong> (Left) Precision across layers, (Middle) Precision vs.
                        Training Iterations, (Right) Precision under viewpoint rotation.
                    </p>
                </div>

                <p>
                    We quantitatively evaluated the correspondence precision on the NAVI dataset. Our analysis
                    highlights three key findings:
                </p>
                <ul
                    style="list-style-type: disc; margin-left: 1.5rem; margin-bottom: 1.5rem; color: var(--color-text-main); font-size: 1.2rem; line-height: 1.625;">
                    <li style="margin-bottom: 0.5rem;">
                        <strong>Correlation with Quality:</strong> As shown in the training dynamics, there is a strong
                        positive correlation between correspondence precision and generation quality (PSNR). As the
                        model learns better correspondence, the visual quality improves, confirming that correspondence
                        underpins synthesis performance.
                    </li>
                    <li style="margin-bottom: 0.5rem;">
                        <strong>CAMEO Improves Correspondence:</strong> Our proposed method, <strong>CAMEO</strong>,
                        explicitly boosts this correspondence precision, surpassing the baseline and achieving accuracy
                        comparable to dedicated discriminative models like DINOv3.
                    </li>
                    <li>
                        <strong>Limitation (Viewpoint Degradation):</strong> Despite these strengths, the baseline's
                        implicit correspondence is fragile. As the relative rotation angle increases (e.g.,
                        &gt;90&deg;), the precision drops sharply. This "viewpoint degradation" necessitates
                        explicit supervision to maintain robustness in challenging scenarios.
                    </li>
                </ul>
            </div>
        </div>
        </div>
    </section>

    <!-- CAMEO Section -->
    <section id="cameo" class="section alt-bg">
        <div class="container">
            <h2 class="section-title">CAMEO</h2>

            <div class="analysis-image-container">
                <img src="assets/teaser.svg" alt="CAMEO Method Overview" class="analysis-image">
            </div>

            <div class="results-caption">
                <p>
                    <strong>CAMEO Framework Overview.</strong> We introduce Correspondence-Attention Alignment,
                    a training framework that explicitly supervises the model's attention maps using dense geometric
                    correspondence priors. By applying supervision to a single optimal attention layer (Layer 10),
                    CAMEO significantly enhances structural understanding and achieves 2x faster convergence.
                </p>
            </div>

            <div class="cameo-description">
                <div>
                    <h3 class="analysis-subtitle">Correspondence-Attention Alignment Loss \(\mathcal{L}_{\text{CAMEO}}\)
                    </h3>
                    <p>
                        At the target layer, we compute the alignment loss by comparing the predicted <strong>3D
                            Self-Attention Map</strong> \(A^l_{i,j}\) with a ground-truth <strong>Geometric
                            Correspondence
                            Map</strong> \(P^{i,j}\). The ground truth is derived from dense pointmaps, ensuring that
                        the
                        attention weights are maximized at physically correct spatial locations across views. This
                        process effectively injects explicit 3D structural priors into the generative model.
                    </p>
                </div>

                <div>
                    <h3 class="analysis-subtitle">Targeted & Model-Agnostic</h3>
                    <p>
                        <strong>Targeted & Simple Supervision:</strong> CAMEO introduces a straightforward yet
                        highly effective supervision strategy. Instead of redesigning the entire architecture, we
                        simply align the cross-view attention map with a pre-computed geometric correspondence map.
                        Crucially, our analysis identified that applying this supervision to a <strong>single target
                            layer (Layer 10)</strong> is sufficient to propagate geometric awareness throughout the
                        entire network.
                    </p>
                    <p>
                        <strong>Model-Agnostic Applicability:</strong> The CAMEO framework is designed to be
                        universally applicable. We demonstrate its effectiveness on both <strong>Stable Video
                            Diffusion</strong> (a UNet-based video generation model) and
                        <strong>Hunyuan-DiT</strong> (a Transformer-based diffusion model). In all cases, CAMEO
                        consistently improves geometric consistency without compromising generation quality.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section id="results" class="section">
        <div class="container">

            <!-- 1. Quantitative Results -->
            <div class="results-block">
                <h2 class="section-title">Quantitative Results</h2>
                <div id="carousel-quan" class="carousel-container">
                    <!-- Injected by JS -->
                </div>
            </div>

            <!-- 2. Qualitative Results -->
            <div class="results-block">
                <h2 class="section-title">Qualitative Results</h2>
                <div id="carousel-qual" class="carousel-container">
                    <!-- Injected by JS -->
                </div>
            </div>

            <!-- 3. Ablation Studies -->
            <div class="results-block">
                <h2 class="section-title">Ablation Studies</h2>
                <div id="carousel-abl" class="carousel-container">
                    <!-- Injected by JS -->
                </div>
            </div>

        </div>
    </section>

    <!-- Citation Section -->
    <section id="citation" class="citation-section">
        <div class="container">
            <h2 class="section-title" style="font-size: 1.5rem; border: none; margin-bottom: 1rem;">Citation</h2>
            <div class="citation-block group">
                <button onclick="copyBibtex()" class="citation-copy-btn">
                    <i class="fa-regular fa-copy"></i> Copy
                </button>
                <pre class="citation-code"><code id="bibtex-text">@article{kwon2026cameo,
  title={CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models},
  author={Kwon, Minkyung and Choi, Jinhyeok and Park, Jiho and Jeon, Seonghu and Jang, Jinhyuk and Seo, Junyoung and Kwak, Min-Seop and Kim, Jin-Hwa and Kim, Seungryong},
  journal={arXiv preprint arXiv:26xx.xxxxx},
  year={2026}
}</code></pre>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>Under Review. Please do not distribute.</p>
        </div>
    </footer>

    <script>
        // Generic Carousel Class
        class Carousel {
            constructor(containerId, data, renderItem) {
                this.container = document.getElementById(containerId);
                this.data = data;
                this.renderItem = renderItem;
                this.currentIndex = 0;
                this.totalSlides = data.length;

                this.init();

                // Handle resize
                window.addEventListener('resize', () => this.updateHeight());

                // Handle image load for height update
                this.container.addEventListener('load', () => this.updateHeight(), true);
            }

            init() {
                this.container.innerHTML = `
                    <div class="carousel-viewport">
                        <div class="carousel-track">
                            ${this.data.map(item => `
                                <div class="carousel-slide">
                                    ${this.renderItem(item)}
                                </div>
                            `).join('')}
                        </div>
                    </div>
                    
                    <button class="carousel-nav-btn prev">
                        <i class="fa-solid fa-chevron-left"></i>
                    </button>
                    <button class="carousel-nav-btn next">
                        <i class="fa-solid fa-chevron-right"></i>
                    </button>

                    <div class="carousel-dots">
                        ${this.data.map((_, i) => `
                            <button class="carousel-dot ${i === 0 ? 'active' : ''}" data-index="${i}"></button>
                        `).join('')}
                    </div>
                `;

                this.track = this.container.querySelector('.carousel-track');
                this.dots = this.container.querySelectorAll('.carousel-dots button');

                this.container.querySelector('.carousel-nav-btn.prev').onclick = () => this.move(-1);
                this.container.querySelector('.carousel-nav-btn.next').onclick = () => this.move(1);
                this.dots.forEach((dot, i) => dot.onclick = () => this.goTo(i));
            }

            move(direction) {
                this.currentIndex = (this.currentIndex + direction + this.totalSlides) % this.totalSlides;
                this.update();
            }

            goTo(index) {
                this.currentIndex = index;
                this.update();
            }

            update() {
                this.track.style.transform = `translateX(-${this.currentIndex * 100}%)`;
                this.dots.forEach((dot, i) => {
                    dot.className = `carousel-dot ${i === this.currentIndex ? 'active' : ''}`;
                });
                this.updateHeight();
            }

            updateHeight() {
                const slides = this.container.querySelectorAll('.carousel-slide');
                if (slides[this.currentIndex]) {
                    const height = slides[this.currentIndex].offsetHeight;
                    this.container.querySelector('.carousel-viewport').style.height = `${height}px`;
                }
            }
        }

        // Data & Render Logic
        const quantitativeData = [
            {
                title: "RealEstate10K",
                desc: "CAMEO achieves a PSNR of 19.4 at only 80k iterations, a level of quality that the baseline model fails to reach even after 160k iterations. This translates to a 2x acceleration in training time.",
                image: "assets/exp_re10k_graph.svg"
            },
            {
                title: "CO3D",
                desc: "On the CO3D dataset, CAMEO consistently outperforms the baseline across all metrics, demonstrating superior geometric consistency and visual fidelity.",
                image: "assets/exp_co3d_graph.svg"
            }
        ];

        const qualitativeData = [
            {
                title: "Complex Geometry",
                desc: "Scenes with intricate geometric structures, such as staircases and railings. CAMEO preserves sharp structural details where baselines often fail.",
                image: "https://images.unsplash.com/photo-1600607687939-ce8a6c25118c?q=80&w=1200&auto=format&fit=crop"
            },
            {
                title: "Large Viewpoint Change",
                desc: "Generating novel views with substantial camera rotations. CAMEO maintains robust 3D consistency even in these 'large-rotation' scenarios.",
                image: "https://images.unsplash.com/photo-1556909212-d5b604d0c90d?q=80&w=1200&auto=format&fit=crop"
            },
            {
                title: "Out-of-Domain Generalization",
                desc: "Zero-shot performance on unseen datasets. CAMEO demonstrates superior generalization capability compared to the baseline.",
                image: "https://images.unsplash.com/photo-1518709268805-4e9042af9f23?q=80&w=1200&auto=format&fit=crop"
            }
        ];

        const ablationData = [
            {
                title: "Effect of Layer Selection",
                desc: "Applying supervision to different layers reveals that Layer 10 is optimal for geometric alignment.",
                image: "https://placehold.co/1200x600/e2e8f0/475569?text=Ablation:+Layer+Selection"
            },
            {
                title: "Loss Weight Analysis",
                desc: "Varying the weight of the CAMEO loss term shows a trade-off between geometric fidelity and texture quality.",
                image: "https://placehold.co/1200x600/e2e8f0/475569?text=Ablation:+Loss+Weight"
            }
        ];

        // Render Functions
        function renderQuantitative(item) {
            return `
                <div class="results-slide-content">
                    <h3 class="results-slide-title">${item.title}</h3>
                    <div class="analysis-image-container" style="padding: 0 20px;">
                        <img src="${item.image}" style="width: 100%; height: auto;" alt="${item.title}">
                    </div>
                    
                    <div class="results-caption">
                        <p>${item.desc}</p>
                    </div>
                </div>
            `;
        }

        function renderImageCard(item) {
            return `
                <div class="results-slide-content">
                    <h3 class="results-slide-title">${item.title}</h3>
                    <div class="analysis-image-container">
                        <img src="${item.image}" class="analysis-image" alt="${item.title}">
                    </div>
                    <div class="results-caption">
                        <p>${item.desc}</p>
                    </div>
                </div>
            `;
        }


        // Chart Generation


        // Initialize
        document.addEventListener('DOMContentLoaded', () => {
            new Carousel('carousel-quan', quantitativeData, renderQuantitative);
            new Carousel('carousel-qual', qualitativeData, renderImageCard);
            new Carousel('carousel-abl', ablationData, renderImageCard);
            initComparisons();
        });

        // Image Comparison Slider Logic
        function initComparisons() {
            var x, i;
            x = document.getElementsByClassName("img-comp-overlay");
            for (i = 0; i < x.length; i++) {
                compareImages(x[i]);
            }

            function compareImages(img) {
                var slider, clicked = 0, w, h;
                // Use parent container for dimensions to be safe
                w = img.parentElement.offsetWidth;
                h = img.parentElement.offsetHeight;

                var overlayImg = img.getElementsByTagName("img")[0];
                if (overlayImg) {
                    overlayImg.style.width = w + "px";
                    overlayImg.style.maxWidth = "none";
                }

                img.style.width = (w / 2) + "px";

                slider = document.createElement("DIV");
                slider.setAttribute("class", "img-comp-slider");
                img.parentElement.insertBefore(slider, img);

                slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
                slider.style.left = (w / 2) - (slider.offsetWidth / 2) + "px";

                slider.addEventListener("mousedown", slideReady);
                window.addEventListener("mouseup", slideFinish);
                slider.addEventListener("touchstart", slideReady);
                window.addEventListener("touchend", slideFinish);

                // Update dimensions on window resize
                window.addEventListener('resize', function () {
                    w = img.parentElement.offsetWidth;
                    h = img.parentElement.offsetHeight;
                    if (overlayImg) {
                        overlayImg.style.width = w + "px";
                    }
                    // Recenter slider vertically
                    slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
                    // Note: We keep the current slider horizontal position (in pixels) 
                    // which might drift on resize, but fixing the image width is most important.
                });

                function slideReady(e) {
                    e.preventDefault();
                    clicked = 1;
                    window.addEventListener("mousemove", slideMove);
                    window.addEventListener("touchmove", slideMove);
                }

                function slideFinish() {
                    clicked = 0;
                }

                function slideMove(e) {
                    var pos;
                    if (clicked == 0) return false;
                    pos = getCursorPos(e);
                    if (pos < 0) pos = 0;
                    if (pos > w) pos = w;
                    slide(pos);
                }

                function getCursorPos(e) {
                    var a, x = 0;
                    e = (e.changedTouches) ? e.changedTouches[0] : e;
                    a = img.getBoundingClientRect();
                    x = e.pageX - a.left;
                    x = x - window.pageXOffset;
                    return x;
                }

                function slide(x) {
                    img.style.width = x + "px";
                    slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + "px";
                }
            }
        }


        // Scroll Spy for Sidebar
        function initScrollSpy() {
            const sections = document.querySelectorAll('section[id]');
            const sidebarLinks = document.querySelectorAll('.sidebar-item');
            const sidebar = document.querySelector('.sidebar');

            const observerOptions = {
                root: null,
                rootMargin: '-50% 0px -50% 0px',
                threshold: 0
            };

            const observer = new IntersectionObserver((entries) => {
                entries.forEach(entry => {
                    if (entry.isIntersecting) {
                        const id = entry.target.getAttribute('id');

                        // Remove active class from all sidebar items
                        sidebarLinks.forEach(link => {
                            link.classList.remove('active');
                        });

                        // Add active class to the corresponding sidebar item
                        const activeLink = document.querySelector(`.sidebar-item[href="#${id}"]`);
                        if (activeLink) {
                            activeLink.classList.add('active');

                            // Update gradient position
                            const linkRect = activeLink.getBoundingClientRect();
                            const sidebarRect = sidebar.getBoundingClientRect();
                            const relativeTop = linkRect.top - sidebarRect.top;
                            sidebar.style.setProperty('--active-position', `${relativeTop - 32}px`);
                        }
                    }
                });
            }, observerOptions);

            sections.forEach(section => {
                observer.observe(section);
            });
        }

        function copyBibtex() {
            const text = document.getElementById('bibtex-text').innerText;
            navigator.clipboard.writeText(text).then(() => {
                const btn = document.querySelector('.citation-copy-btn');
                const original = btn.innerHTML;
                btn.innerHTML = '<i class="fa-solid fa-check"></i> Copied!';
                setTimeout(() => {
                    btn.innerHTML = original;
                }, 2000);
            });
        }

        // Initialize scroll spy when DOM is ready
        // Initialize charts
        document.addEventListener('DOMContentLoaded', () => {
            initComparisons();
            initScrollSpy();
        });


    </script>
</body>

</html>
```