<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models</title>
    <meta name="description" content="Project page for CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models (Under Review)">
    
    <!-- Fonts and Icons -->
    <link href="https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&family=Noto+Sans+KR:wght@400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        teal: {
                            50: '#DCF4EC',
                            100: '#DCF4EC',
                            200: '#b6ebe2',
                            300: '#8fdcd4',
                            400: '#65c9c3',
                            500: '#3eaeb0',
                            600: '#22869A',
                            700: '#1b6b7b',
                            800: '#15505c',
                            900: '#0f3840',
                        }
                    }
                }
            }
        }
    </script>
    
    <style>
        body {
            font-family: 'Google Sans', sans-serif;
            background-color: #ffffff;
            color: #1e293b;
        }
        .abstract-text {
            font-family: 'Google Sans', sans-serif;
            text-align: justify;
        }
        /* Paper Tone: Teal/Cyan Gradient */
        .gradient-text {
            background: linear-gradient(to right, #22869A, #1b6b7b);
            -webkit-background-clip: text;
            background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        /* Image Comparison Slider Styles */
        .img-comp-container {
            position: relative;
            height: 400px; /* Increased height for full width impact */
            overflow: hidden;
            border-radius: 0; /* Removed radius for full bleed */
            border: none;
            cursor: ew-resize;
        }
        .img-comp-img {
            position: absolute;
            width: 100%;
            height: 100%;
            overflow: hidden;
        }
        .img-comp-img img {
            display: block;
            width: 100%;
            height: 100%;
            object-fit: cover;
        }
        .img-comp-slider {
            position: absolute;
            z-index: 9;
            cursor: ew-resize;
            width: 40px;
            height: 40px;
            background-color: white;
            border-radius: 50%;
            border: 2px solid #22869A; /* Teal color */
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            display: flex;
            align-items: center;
            justify-content: center;
            /* No shadow, just border */
            border: 2px solid #22869A;
        }
        .img-comp-slider::before {
            content: '\f337';
            font-family: 'Font Awesome 6 Free';
            font-weight: 900;
            color: #22869A;
        }
        /* Custom Scrollbar */
        ::-webkit-scrollbar {
            width: 8px;
        }
        ::-webkit-scrollbar-track {
            background: #f1f1f1;
        }
        ::-webkit-scrollbar-thumb {
            background: #b6ebe2;
            border-radius: 4px;
        }
        ::-webkit-scrollbar-thumb:hover {
            background: #8fdcd4;
        }
        
        /* Diagram Styles */
        .diffusion-block {
            position: relative;
            background-color: #f1f5f9; /* slate-100 */
            border: 1px solid #cbd5e1; /* slate-300 */
            border-radius: 0.5rem;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 0.75rem;
            color: #475569;
            font-weight: 500;
            writing-mode: vertical-lr;
            transform: rotate(180deg);
            height: 120px;
            width: 40px;
            transition: all 0.3s ease;
        }
        .diffusion-block.highlight {
            background-color: #DCF4EC; /* teal-100 */
            border: 2px solid #22869A; /* teal-600 */
            color: #22869A;
            font-weight: 700;
            z-index: 10;
        }
        .pipeline-arrow {
            color: #94a3b8;
            font-size: 1.2rem;
        }
        .grid-map {
            display: grid;
            grid-template-columns: repeat(6, 1fr);
            gap: 1px;
            width: 100%;
            aspect-ratio: 1;
            background-color: #e2e8f0;
            border: 1px solid #cbd5e1;
        }
        .grid-cell {
            background-color: #f8fafc;
        }
        .grid-cell.active-teal {
            background-color: #65c9c3;
        }
        .grid-cell.active-red {
            background-color: #f87171;
        }
        .grid-cell.active-mix {
            background: linear-gradient(135deg, #65c9c3 50%, #f87171 50%);
        }
    </style>
</head>
<body>

    <!-- Navbar -->
    <nav class="bg-white border-b border-slate-200 sticky top-0 z-50">
        <div class="w-full px-4 sm:px-6 lg:px-8"> <!-- Full width container -->
            <div class="flex justify-between h-16">
                <div class="flex items-center">
                    <span class="font-bold text-xl tracking-tight text-slate-800">CAMEO</span>
                </div>
                <div class="flex items-center space-x-6">
                    <a href="#abstract" class="text-slate-600 hover:text-teal-700 font-medium transition">Abstract</a>
                    <a href="#method" class="text-slate-600 hover:text-teal-700 font-medium transition">Method</a>
                    <a href="#results" class="text-slate-600 hover:text-teal-700 font-medium transition">Results</a>
                </div>
            </div>
        </div>
    </nav>

    <!-- Header Section -->
    <section class="pt-16 pb-0 text-center w-full"> <!-- Removed px and max-w limitations on section -->
        <div class="max-w-4xl mx-auto px-4 mb-12"> <!-- Text stays constrained -->
            <h1 class="text-4xl md:text-5xl font-bold mb-4 leading-tight text-slate-900">
                <span class="gradient-text">CAMEO</span>: Correspondence-Attention Alignment for Multi-View Diffusion Models
            </h1>
            <p class="text-xl text-teal-700 font-semibold mb-6">Under Review</p>
            
            <!-- Authors -->
            <div class="flex flex-wrap justify-center gap-x-4 gap-y-2 text-lg mb-6 max-w-3xl mx-auto">
                <span class="text-slate-700 font-medium whitespace-nowrap">Minkyung Kwon<sup>1</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Jinhyeok Choi<sup>1</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Jiho Park<sup>2</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Seonghu Jeon<sup>3</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Jinhyuk Jang<sup>1</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Junyoung Seo<sup>1</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Min-Seop Kwak<sup>1</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Jin-Hwa Kim<sup>4</sup></span>
                <span class="text-slate-700 font-medium whitespace-nowrap">Seungryong Kim<sup>1</sup></span>
            </div>

            <div class="flex flex-wrap justify-center gap-4 mb-8 text-slate-500 text-sm">
                <span><sup>1</sup>KAIST</span>
                <span><sup>2</sup>Yonsei University</span>
                <span><sup>3</sup>Korea University</span>
                <span><sup>4</sup>NAVER</span>
            </div>

            <!-- Link Buttons -->
            <div class="flex justify-center gap-4 mb-12">
                <a href="#" class="flex items-center gap-2 px-6 py-2 bg-slate-900 text-white rounded border border-slate-900 hover:bg-slate-700 transition">
                    <i class="fa-solid fa-file-pdf"></i> Paper
                </a>
                <a href="#" class="flex items-center gap-2 px-6 py-2 bg-white text-slate-800 rounded border border-slate-300 hover:bg-slate-50 transition">
                    <i class="fa-brands fa-github"></i> Code (Coming Soon)
                </a>
                <a href="#bibtex" class="flex items-center gap-2 px-6 py-2 bg-white text-slate-800 rounded border border-slate-300 hover:bg-slate-50 transition">
                    <i class="fa-solid fa-quote-right"></i> BibTeX
                </a>
            </div>
        </div>

        <!-- Teaser Image: Full Width (Bleed) -->
        <div class="w-full bg-white overflow-hidden relative py-0 px-4 sm:px-6 lg:px-8 max-w-[1600px] mx-auto">
            
            <!-- Image Comparison Sliders in Header/Teaser Area -->
            <div class="grid md:grid-cols-2 gap-4 w-full mt-8 mb-8">
                <!-- Result 1 -->
                <div class="relative group">
                    <div class="img-comp-container h-[500px]" id="compare1">
                        <div class="img-comp-img">
                            <!-- Placeholder for CAMEO Result -->
                            <img src="https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?q=80&w=1600&auto=format&fit=crop" alt="CAMEO (Ours)">
                            <div class="absolute bottom-4 right-4 bg-teal-900/90 text-white px-3 py-1 text-sm font-medium border border-teal-500 backdrop-blur-sm">CAMEO</div>
                        </div>
                        <div class="img-comp-img img-comp-overlay">
                            <!-- Placeholder for Baseline Result (Blurry/Distorted) -->
                            <img src="https://images.unsplash.com/photo-1560448204-e02f11c3d0e2?q=80&w=1600&auto=format&fit=crop&blur=50" style="filter: blur(4px) contrast(1.2);" alt="Baseline">
                             <div class="absolute bottom-4 left-4 bg-slate-900/90 text-white px-3 py-1 text-sm font-medium border border-slate-500 backdrop-blur-sm">Baseline</div>
                        </div>
                    </div>
                    <div class="absolute top-4 left-1/2 -translate-x-1/2 bg-black/50 text-white px-2 py-1 text-xs rounded backdrop-blur-sm">Large Viewpoint Change</div>
                </div>

                <!-- Result 2 -->
                <div class="relative group">
                    <div class="img-comp-container h-[500px]" id="compare2">
                        <div class="img-comp-img">
                            <img src="https://images.unsplash.com/photo-1586023492125-27b2c045efd7?q=80&w=1600&auto=format&fit=crop" alt="CAMEO (Ours)">
                            <div class="absolute bottom-4 right-4 bg-teal-900/90 text-white px-3 py-1 text-sm font-medium border border-teal-500 backdrop-blur-sm">CAMEO</div>
                        </div>
                        <div class="img-comp-img img-comp-overlay">
                            <img src="https://images.unsplash.com/photo-1586023492125-27b2c045efd7?q=80&w=1600&auto=format&fit=crop" style="filter: hue-rotate(30deg) blur(2px);" alt="Baseline">
                            <div class="absolute bottom-4 left-4 bg-slate-900/90 text-white px-3 py-1 text-sm font-medium border border-slate-500 backdrop-blur-sm">Baseline</div>
                        </div>
                    </div>
                     <div class="absolute top-4 left-1/2 -translate-x-1/2 bg-black/50 text-white px-2 py-1 text-xs rounded backdrop-blur-sm">Complex Geometry</div>
                </div>
            </div>

        </div>
    </section>

    <!-- Abstract -->
    <section id="abstract" class="max-w-5xl mx-auto px-4 py-16">
        <h2 class="text-3xl font-bold text-center mb-8 text-slate-900">Abstract</h2>
        <div class="text-xl leading-relaxed text-slate-800 text-justify">
            <p class="mb-6">
                Multi-view diffusion models have recently established themselves as a powerful paradigm for novel view synthesis, generating diverse images with high visual fidelity. However, the underlying mechanisms that enable these models to maintain geometric consistency across different viewpoints have remained largely unexplored. In this work, we conduct an in-depth analysis of the 3D self-attention layers within these models. We empirically verify that <strong>geometric correspondence naturally emerges in specific attention layers</strong> during training, allowing the model to attend to spatially corresponding regions across reference and target views.
            </p>
            <p>
                Despite this emergent capability, our analysis reveals that the implicit correspondence signal is often incomplete and fragile, particularly degrading under scenarios involving complex geometries or large viewpoint changes. Addressing this limitation, we introduce <strong>CAMEO</strong> (Correspondence-Attention Alignment), a training framework that explicitly supervises the model's attention maps using dense geometric correspondence priors. By applying this supervision to just a single, optimal attention layer (Layer 10), CAMEO significantly enhances the model's structural understanding. Our experiments demonstrate that CAMEO <strong>reduces the training iterations required for convergence by 50%</strong> while consistently outperforming baseline models in geometric fidelity on challenging datasets such as RealEstate10K and CO3D.
            </p>
        </div>
    </section>
    
    <!-- Key Insight Section -->
    <section id="insight" class="w-full py-16 border-t border-slate-200">
        <div class="max-w-6xl mx-auto px-4">
             <h2 class="text-3xl font-bold text-center mb-12 text-slate-900">Correspondence in Attention</h2>
             
             <!-- Layer Analysis Image (Placeholder for the wide image provided by user) -->
             <div class="w-full mb-10">
                 <!-- User should replace this src with their actual image file, e.g., assets/layer_analysis.png -->
                 <img src="assets/layer_analysis.png" onerror="this.src='https://placehold.co/1200x300/e2e8f0/475569?text=Layer-wise+Attention+Analysis+(Target+...+Layer+7)'" class="w-full h-auto object-contain" alt="Layer-wise Attention Analysis">
             </div>

             <div class="text-xl text-slate-800 leading-relaxed space-y-8">
                <div>
                    <h3 class="text-2xl font-bold text-slate-900 mb-2">The Lack of Geometry in Early Layers</h3>
                    <p>
                        Our layer-wise analysis of the diffusion U-Net reveals that the shallow layers (e.g., Layers 2â€“6) are primarily focused on low-level features rather than spatial relationships. As illustrated in the visualizations, the cross-view attention maps in these layers exhibit significant noise and fail to establish meaningful connections between the query points in the target view and their corresponding regions in the reference views. This indicates that geometric guidance is largely absent in the initial stages of the network's processing.
                    </p>
                </div>
                
                <div>
                    <h3 class="text-2xl font-bold text-teal-700 mb-2">The Emergence of Correspondence in Layer 10</h3>
                    <p>
                        A distinct pattern emerges as we analyze deeper layers. Specifically, at <strong>Layer 10</strong>, the model demonstrates a strong, emergent ability to capture geometric correspondence. Even without explicit supervision, the attention mechanism in this layer spontaneously focuses on geometrically corresponding points across different views. Quantitative evaluations show that the correspondence precision of this specific layer is comparable to that of dedicated visual foundation models like DINOv3, suggesting it serves as the primary internal carrier of geometric information within the diffusion model.
                    </p>
                </div>

                <div>
                    <h3 class="text-2xl font-bold text-slate-900 mb-2">The Degradation under Large Viewpoint Changes</h3>
                    <p>
                        While Layer 10 exhibits emergent geometric awareness, this implicit signal is not robust. Our comparative analysis with ground-truth geometry from VGGT reveals a significant performance gap: as the relative rotation angle between views increases, the precision of the attention map's correspondence drops sharply. This fragility under large viewpoint changes explains why standard multi-view diffusion models often produce structural inconsistencies or 'hallucinations' when synthesizing views from drastically different angles.
                    </p>
                </div>
             </div>
        </div>
    </section>

    <!-- Method Section: Full Width -->
    <section id="method" class="w-full py-16 bg-white border-t border-slate-200">
        <div class="max-w-5xl mx-auto px-4 mb-10">
            <h2 class="text-3xl font-bold text-center text-slate-900">Method Overview</h2>
        </div>
        
        <div class="w-full py-8 px-0 mb-12">
            <div class="max-w-[1600px] mx-auto flex flex-col lg:flex-row items-center gap-12 px-4">
                <!-- Left: Method Overview Image -->
                <div class="w-full lg:w-3/5 flex items-center justify-center">
                    <img src="assets/teaser.svg" class="w-full h-auto object-contain" alt="CAMEO Method Overview">
                </div>
                
                <!-- Right: Explanation Text -->
                <div class="w-full lg:w-2/5 text-xl text-slate-800 flex flex-col justify-center space-y-8">
                    <div>
                        <h3 class="text-2xl font-bold text-slate-900 mb-4">Correspondence-Attention Alignment Loss (L<sub>CAMEO</sub>)</h3>
                        <p class="leading-relaxed">
                            At the target layer, we compute the alignment loss by comparing the predicted <strong>3D Self-Attention Map</strong> (A) with a ground-truth <strong>Geometric Correspondence Map</strong> (P). The ground truth is derived from dense pointmaps, ensuring that the attention weights are maximized at physically correct spatial locations across views. This process effectively injects explicit 3D structural priors into the generative model.
                        </p>
                    </div>
                    
                    <div>
                        <h3 class="text-2xl font-bold text-slate-900 mb-4">Targeted & Model-Agnostic</h3>
                        <p class="leading-relaxed mb-4">
                            <strong>Targeted & Simple Supervision:</strong> CAMEO introduces a straightforward yet highly effective supervision strategy. Instead of redesigning the entire architecture, we simply align the cross-view attention map with a pre-computed geometric correspondence map. Crucially, our analysis identified that applying this supervision to a <strong>single target layer (Layer 10)</strong> is sufficient to propagate geometric awareness throughout the entire network.
                        </p>
                        <p class="leading-relaxed">
                            <strong>Model-Agnostic Applicability:</strong> The CAMEO framework is designed to be universally applicable to various multi-view diffusion architectures. We demonstrate its versatility by integrating it into <strong>CAT3D</strong> (a U-Net based model), <strong>MVGenMaster</strong> (a geometry-conditioned model), and <strong>Hunyuan-DiT</strong> (a Transformer-based diffusion model). In all cases, CAMEO consistently improves geometric consistency and training efficiency without requiring model-specific modifications.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Gallery Section -->
    <section id="results-gallery" class="w-full py-16 border-t border-slate-200">
        <div class="max-w-5xl mx-auto px-4 mb-12 text-center">
            <h2 class="text-3xl font-bold text-slate-900 mb-4">Results Gallery</h2>
            <p class="text-xl text-slate-700">CAMEO consistently outperforms baselines in challenging scenarios.</p>
        </div>

        <div class="max-w-7xl mx-auto px-4 grid md:grid-cols-3 gap-8">
             <!-- Case 1 -->
             <div class="flex flex-col">
                 <div class="h-64 bg-slate-100 mb-4 overflow-hidden group relative">
                    <img src="https://images.unsplash.com/photo-1600607687939-ce8a6c25118c?q=80&w=800&auto=format&fit=crop" class="w-full h-full object-cover" alt="Complex Geometry">
                    <div class="absolute inset-0 bg-black/70 flex items-center justify-center opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        <p class="text-white text-center px-4">Hover over the image to reveal the underlying attention mechanism. While the baseline model's attention is often scattered, CAMEO's attention precisely locks onto geometrically corresponding regions.</p>
                    </div>
                 </div>
                 <h3 class="text-2xl font-bold text-slate-900 mb-2">Complex Geometry</h3>
                 <p class="text-lg text-slate-700 leading-relaxed">
                    Scenes with intricate geometric structures, such as staircases, railings, and window frames, pose a significant challenge for baseline models, often resulting in blurred or geometrically implausible artifacts. CAMEO effectively resolves these issues, preserving sharp structural details and ensuring that straight lines and repetitive patterns remain consistent across generated views.
                 </p>
             </div>

             <!-- Case 2 -->
             <div class="flex flex-col">
                 <div class="h-64 bg-slate-100 mb-4 overflow-hidden group relative">
                    <img src="https://images.unsplash.com/photo-1556909212-d5b604d0c90d?q=80&w=800&auto=format&fit=crop" class="w-full h-full object-cover" alt="Large Viewpoint Change">
                    <div class="absolute inset-0 bg-black/70 flex items-center justify-center opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        <p class="text-white text-center px-4">Hover over the image to reveal the underlying attention mechanism. While the baseline model's attention is often scattered, CAMEO's attention precisely locks onto geometrically corresponding regions.</p>
                    </div>
                 </div>
                 <h3 class="text-2xl font-bold text-slate-900 mb-2">Large Viewpoint Change</h3>
                 <p class="text-lg text-slate-700 leading-relaxed">
                    Generating novel views with substantial camera rotations (e.g., viewing an object from the opposite side) typically leads to semantic drifting or loss of object identity in standard models. CAMEO maintains robust 3D consistency even in these 'large-rotation' scenarios, accurately reconstructing occluded regions by leveraging the enforced attention correspondence.
                 </p>
             </div>

             <!-- Case 3 -->
             <div class="flex flex-col">
                 <div class="h-64 bg-slate-100 mb-4 overflow-hidden group relative">
                    <img src="https://images.unsplash.com/photo-1518709268805-4e9042af9f23?q=80&w=800&auto=format&fit=crop" class="w-full h-full object-cover" alt="Out-of-Domain Generalization">
                    <div class="absolute inset-0 bg-black/70 flex items-center justify-center opacity-0 group-hover:opacity-100 transition-opacity duration-300">
                        <p class="text-white text-center px-4">Hover over the image to reveal the underlying attention mechanism. While the baseline model's attention is often scattered, CAMEO's attention precisely locks onto geometrically corresponding regions.</p>
                    </div>
                 </div>
                 <h3 class="text-2xl font-bold text-slate-900 mb-2">Out-of-Domain Generalization</h3>
                 <p class="text-lg text-slate-700 leading-relaxed">
                    To test generalization capability, we evaluated the models on the unseen DTU dataset without any fine-tuning. CAMEO demonstrates superior zero-shot performance compared to the baseline, indicating that our explicit supervision helps the model learn a more generalized and robust understanding of 3D geometry that extends beyond the training data distribution.
                 </p>
             </div>
        </div>
    </section>

    <!-- Efficiency Analysis Section -->
    <section id="efficiency" class="w-full py-16 border-t border-slate-200">
         <div class="max-w-6xl mx-auto px-4 flex flex-col md:flex-row items-start gap-16">
             <div class="w-full md:w-1/2">
                 <h2 class="text-3xl font-bold text-slate-900 mb-6">Efficiency Analysis</h2>
                 <p class="text-xl text-slate-800 leading-relaxed mb-8">
                     One of the most significant advantages of CAMEO is its impact on training efficiency. By providing a clear geometric signal, CAMEO accelerates the convergence of the diffusion model. Quantitative results show that CAMEO achieves a PSNR of <strong>19.4 at only 80k iterations</strong>, a level of quality that the baseline model fails to reach even after <strong>160k iterations</strong>. This translates to a <strong>2x acceleration</strong> in training time, significantly reducing the computational resources required to train high-quality multi-view diffusion models.
                 </p>
                 <div class="flex items-center gap-6">
                     <div>
                         <span class="block text-5xl font-bold text-teal-600 mb-2">2x</span>
                         <span class="text-lg font-bold text-slate-700 uppercase tracking-wide">Faster Convergence</span>
                     </div>
                 </div>
             </div>
             <div class="w-full md:w-1/2 flex items-center justify-center">
                 <!-- Placeholder Chart: Simple Image Layout -->
                 <div class="w-full bg-slate-50 h-80 flex items-center justify-center border border-slate-200">
                      <!-- User should replace this with assets/efficiency_chart.png -->
                      <div class="text-center text-slate-400">
                          <i class="fa-solid fa-chart-line text-5xl mb-4"></i>
                          <p class="text-xl">Performance vs. Iterations Chart</p>
                          <p class="text-sm">(Place efficiency chart image here)</p>
                      </div>
                 </div>
             </div>
         </div>
    </section>

    <!-- BibTeX -->
    <section id="bibtex" class="max-w-4xl mx-auto px-4 py-12 border-t border-slate-200 mt-8">
        <h2 class="text-xl font-bold mb-4 text-slate-800">BibTeX</h2>
        <div class="bg-slate-50 text-slate-600 p-4 rounded border border-slate-200 overflow-x-auto relative group">
            <button onclick="copyBibtex()" class="absolute top-2 right-2 bg-white border border-slate-300 hover:bg-slate-100 text-slate-600 px-2 py-1 rounded text-xs transition opacity-0 group-hover:opacity-100">
                <i class="fa-regular fa-copy"></i> Copy
            </button>
            <pre class="font-mono text-xs leading-relaxed"><code id="bibtex-text">@article{kwon2026cameo,
  title={CAMEO: Correspondence-Attention Alignment for Multi-View Diffusion Models},
  author={Kwon, Minkyung and Choi, Jinhyeok and Park, Jiho and Jeon, Seonghu and Jang, Jinhyuk and Seo, Junyoung and Kwak, Min-Seop and Kim, Jin-Hwa and Kim, Seungryong},
  journal={arXiv preprint arXiv:26xx.xxxxx},
  year={2026}
}</code></pre>
        </div>
    </section>

    <!-- Footer -->
    <footer class="bg-white border-t border-slate-200 py-8 mt-8">
        <div class="max-w-4xl mx-auto px-4 text-center text-slate-400 text-sm">
            <p>
                Under Review. Please do not distribute.
            </p>
        </div>
    </footer>

    <!-- Scripts -->
    <script>
        // Image Comparison Slider Logic
        function initComparisons() {
            var x, i;
            x = document.getElementsByClassName("img-comp-overlay");
            for (i = 0; i < x.length; i++) {
                compareImages(x[i]);
            }

            function compareImages(img) {
                var slider, clicked = 0, w, h;
                /* Get the width and height of the img element */
                w = img.offsetWidth;
                h = img.offsetHeight;
                
                /* Fix the width of the image inside the overlay div so it doesn't shrink */
                var overlayImg = img.getElementsByTagName("img")[0];
                if (overlayImg) {
                    overlayImg.style.width = w + "px";
                    overlayImg.style.maxWidth = "none"; // Ensure max-width doesn't constrain it
                }
                
                /* Set the width of the img element to 50%: */
                img.style.width = (w / 2) + "px";
                
                /* Create slider: */
                slider = document.createElement("DIV");
                slider.setAttribute("class", "img-comp-slider");
                /* Insert slider */
                img.parentElement.insertBefore(slider, img);
                
                /* Position the slider in the middle: */
                slider.style.top = (h / 2) - (slider.offsetHeight / 2) + "px";
                slider.style.left = (w / 2) - (slider.offsetWidth / 2) + "px";

                /* Execute a function when the mouse button is pressed: */
                slider.addEventListener("mousedown", slideReady);
                /* And another function when the mouse button is released: */
                window.addEventListener("mouseup", slideFinish);
                /* Or touched (for touch screens: */
                slider.addEventListener("touchstart", slideReady);
                /* And released (for touch screens: */
                window.addEventListener("touchend", slideFinish);

                function slideReady(e) {
                    /* Prevent any other actions that may occur when moving over the image: */
                    e.preventDefault();
                    /* The slider is now clicked and ready to move: */
                    clicked = 1;
                    /* Execute a function when the slider is moved: */
                    window.addEventListener("mousemove", slideMove);
                    window.addEventListener("touchmove", slideMove);
                }

                function slideFinish() {
                    /* The slider is no longer clicked: */
                    clicked = 0;
                }

                function slideMove(e) {
                    var pos;
                    /* If the slider is no longer clicked, exit this function: */
                    if (clicked == 0) return false;
                    /* Get the cursor's x position: */
                    pos = getCursorPos(e);
                    /* Prevent the slider from being positioned outside the image: */
                    if (pos < 0) pos = 0;
                    if (pos > w) pos = w;
                    /* Execute a function that will resize the overlay image according to the cursor: */
                    slide(pos);
                }

                function getCursorPos(e) {
                    var a, x = 0;
                    e = (e.changedTouches) ? e.changedTouches[0] : e;
                    /* Get the x positions of the image: */
                    a = img.getBoundingClientRect();
                    /* Calculate the cursor's x coordinate, relative to the image: */
                    x = e.pageX - a.left;
                    /* Consider any page scrolling: */
                    x = x - window.pageXOffset;
                    return x;
                }

                function slide(x) {
                    /* Resize the image: */
                    img.style.width = x + "px";
                    /* Position the slider: */
                    slider.style.left = img.offsetWidth - (slider.offsetWidth / 2) + "px";
                }
            }
        }

        // Initialize sliders when DOM is ready
        document.addEventListener('DOMContentLoaded', initComparisons);
        
        // Handle window resize for sliders
        window.addEventListener('resize', function() {
            // Reset comparisons on resize (simplified)
            // Ideally, we'd re-calculate widths, but reloading or CSS flex handles most.
            // For the JS slider, a reload or re-init might be needed if dimensions drastically change.
        });

        // Copy BibTeX
        function copyBibtex() {
            const text = document.getElementById('bibtex-text').innerText;
            navigator.clipboard.writeText(text).then(() => {
                alert('BibTeX copied to clipboard!');
            });
        }
    </script>
</body>
</html>